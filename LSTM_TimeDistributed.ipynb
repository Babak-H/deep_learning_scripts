{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***keras.layers.TimeDistributed(layer)\n",
    "\n",
    "This wrapper applies a layer to every temporal slice of an input.\n",
    "The input should be at least 3D, and the dimension of index one will be considered to be the \n",
    "temporal dimension.\n",
    "Consider a batch of 32 samples, where each sample is a sequence of 10 vectors of 16 dimensions. \n",
    "The batch input shape \n",
    "of the layer is then (32, 10, 16), and the input_shape, not including the samples dimension, is \n",
    "(10, 16).\n",
    "You can then use TimeDistributed to apply a Dense layer to each of the 10 timesteps, independently.\n",
    "\n",
    "as the first layer in a model<br>\n",
    "    model = Sequential()<br>\n",
    "    model.add(TimeDistributed(Dense(8), input_shape=(10, 16)))<br>\n",
    "\n",
    "now model.output_shape == (None, 10, 8)\n",
    "\n",
    "The output will then have shape (32, 10, 8).\n",
    "In subsequent layers, there is no need for the input_shape:<br>\n",
    "    model.add(TimeDistributed(Dense(32)))<br>\n",
    "now model.output_shape == (None, 10, 32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.  0.2 0.4 0.6 0.8]\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "length = 5\n",
    "seq = array([i/float(length) for i in range(length)])\n",
    "print(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 10, 1)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import LSTM\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(5, input_shape = (10, 20), return_sequences = True))\n",
    "model.add(TimeDistributed(Dense(1)))\n",
    "print(model.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 10, 1)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(5, input_shape = (10, 20), return_sequences = True))\n",
    "model.add((Dense(1)))\n",
    "print(model.output_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In keras - while building a sequential model - usually the second dimension \n",
    "(one after sample dimension) - is related to a time dimension. This means that if for example, \n",
    "your data is 5-dim with (sample, time, width, length, channel) you could apply a convolutional \n",
    "layer using TimeDistributed (which is applicable to 4-dim with (sample, width, length, channel)) \n",
    "along a time dimension (applying the same layer to each time slice) in order to obtain 5-d output.\n",
    "\n",
    "The case with Dense is that in keras from version 2.0 Dense is by default applied to only last \n",
    "dimension (e.g. if you apply Dense(10) to input with shape (n, m, o, p) you'll get output with \n",
    "shape (n, m, o, 10)) so in your case Dense and TimeDistributed(Dense) are equivalent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
