{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#  Convolutional Neural Networks\n",
    "#  is it Cat or Dog\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import numpy as np\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bob\\AppData\\Local\\conda\\conda\\envs\\Deep_learn\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(64, 64, 3..., activation=\"relu\")`\n",
      "  \n",
      "C:\\Users\\Bob\\AppData\\Local\\conda\\conda\\envs\\Deep_learn\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "classifier = Sequential()\n",
    "# number of filters   width, heights of each filter\n",
    "# input shape forces all images to have same pixel size/format 64x64 size of image by pixels\n",
    "# 3 : colored images (RGB)   1: black/white images\n",
    "# relu activation turns all negative pixel values into zero\n",
    "classifier.add(Convolution2D(32, 3, 3, input_shape=(64, 64, 3), activation='relu'))\n",
    "# keras.layers.MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid', data_format=None)\n",
    "# pool_size =(x, y)   x : downsize vertical by this   y : downsize horizontal by this\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "classifier.add(Convolution2D(32, 3, 3, activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# flattening layer\n",
    "classifier.add(Flatten())\n",
    "# fully connected layer\n",
    "classifier.add(Dense(128, activation='relu'))\n",
    "# final layer, since its only dog or cat (binary) we can use sigmoid instead of softmax\n",
    "classifier.add(Dense(1, activation='sigmoid'))\n",
    "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "filepath=\"weights.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=0, save_best_only=True, mode='max')\n",
    "callback_list = []\n",
    "callback_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# image augmentation\n",
    "# this function will add changes to our images so that we have more images (based on our dataset)\n",
    "# this is useful when number of training elements in our dataset is too low\n",
    "train_datagen = ImageDataGenerator(\n",
    "    # here we rescale images, change the zoom and flip horizontal images so we have same image but\n",
    "    # the model will view it as new data for training\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "# same as above but for test dataset\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# here we mention where to get the data from (location)\n",
    "# size of our images\n",
    "# batche size\n",
    "# if it is two classes binary / more than two it is categorical\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "        'dataset/training_set',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "        'dataset/test_set',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our data is structured this way:\n",
    "#     dataset -> training_set -> cats -> images\n",
    "#                             -> dogs -> images\n",
    "#             -> test_set -> cats -> images\n",
    "#                         -> dogs -> images\n",
    "# this program will detect label of the image based on name of folder it is located in (cat or dog)\n",
    "# so we wont need to feed it label of the images manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "8000/8000 [==============================] - 1128s 141ms/step - loss: 0.3611 - acc: 0.8315 - val_loss: 0.5843 - val_acc: 0.8044\n",
      "Epoch 2/5\n",
      "8000/8000 [==============================] - 1233s 154ms/step - loss: 0.1056 - acc: 0.9603 - val_loss: 0.9342 - val_acc: 0.8075\n",
      "Epoch 3/5\n",
      "8000/8000 [==============================] - 1164s 145ms/step - loss: 0.0514 - acc: 0.9815 - val_loss: 1.0517 - val_acc: 0.8009\n",
      "Epoch 4/5\n",
      "8000/8000 [==============================] - 1144s 143ms/step - loss: 0.0375 - acc: 0.9866 - val_loss: 1.1808 - val_acc: 0.7951\n",
      "Epoch 5/5\n",
      "8000/8000 [==============================] - 1135s 142ms/step - loss: 0.0306 - acc: 0.9897 - val_loss: 1.3091 - val_acc: 0.7950\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d2c3656940>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is the method that will train our data and test it on validation (test) set\n",
    "classifier.fit_generator(\n",
    "        training_set,\n",
    "        # how many training data do we have     \n",
    "        steps_per_epoch=8000,\n",
    "        epochs=5,\n",
    "        validation_data=test_set,\n",
    "        # how many testing data do we have     \n",
    "        validation_steps=2000,callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cats': 0, 'dogs': 1}\n"
     ]
    }
   ],
   "source": [
    "# loading the image file and changing its size to 64x64 same as our training data\n",
    "test_image = image.load_img('dataset/single_prediction/cat_or_dog_2.jpg', target_size=(64,64))\n",
    "# turning the image into 3d array with RGB layers\n",
    "test_image = image.img_to_array(test_image)\n",
    "# since our classifer recieves data in a batch we need to add 4th dimension (batch) to our single prediction data\n",
    "test_image = np.expand_dims(test_image, axis=0)\n",
    "\n",
    "result = classifier.predict(test_image)\n",
    "print(training_set.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]]\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
